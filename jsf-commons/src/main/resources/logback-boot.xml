<?xml version="1.0" encoding="UTF-8"?>
<configuration>

    <!-- 读取Springboot application.yml配置 -->
    <springProperty name="LOG_PATH" source="logging.path" defaultValue="./logs" />
    <springProperty name="APPLICATION" source="spring.application.name" defaultValue="API" />
    <springProperty name="APPLICATION_SIMPLE" source="spring.application.simple" defaultValue="api" />
    <!-- 日志显示格式 -->
    <property name="PATTERN" value="%d{yyyy-MM-dd HH:mm:ss.SSS} %level [%thread] [%X{server}][%X{rid}] %logger{50}:%L - %msg%n"></property>
    <!--带颜色显示，但logstash等日志解析不能正常工作-->
    <!--<property name="PATTERN" value="%d{yyyy-MM-dd HH:mm:ss.SSS} %highlight(%-5level) [%thread] [%X{server}][%X{rid}] %cyan(%logger{50}:%L) - %msg%n"></property>-->
    <!-- 日志文件名称 读取环境变量${app.name:-jsf} -->
    <property name="FILE_NAME" value="${APPLICATION}"></property>
    <property name="ERROR_NAME" value="${APPLICATION}.error"></property>

    <!-- 开发环境 -->
    <!-- 控制台打印+写入日志文件 -->
    <springProfile name="${APPLICATION_SIMPLE}-dev">
        <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
            <encoder>
                <pattern>${PATTERN}</pattern>
            </encoder>
        </appender>

        <!-- 分布式flume日志 -->
        <!--<appender name="flume" class="com.jsf.system.flume.FlumeLogstashV1Appender">
            <flumeAgents>
                192.168.1.199:8888,
            </flumeAgents>
            <flumeProperties>
                connect-timeout=4000;
                request-timeout=8000
            </flumeProperties>
            <batchSize>2048</batchSize>
            <reportingWindow>20480</reportingWindow>
            <additionalAvroHeaders>
                myHeader=myValue
            </additionalAvroHeaders>
            <application>jsf-app</application>
            <layout class="ch.qos.logback.classic.PatternLayout">
                <pattern>${PATTERN}</pattern>
            </layout>
        </appender>-->

        <!-- 分布式ELK日志 -->
        <!--<appender name="elk" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
            <destination>vm:9250</destination>
            <encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder">
                <customFields>{"logtype":"ext","logsrv":"srv10"}</customFields>
            </encoder>
        </appender>-->

        <!-- *flume和elk方式已废弃，推荐使用filebeat采集并归集到ELK -->

        <appender name="syslog" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <file>${LOG_PATH}/${FILE_NAME}.log</file>
            <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
                <fileNamePattern>${LOG_PATH}/%d{yyyy-MM-dd}/${FILE_NAME}.%i.log</fileNamePattern>
                <maxFileSize>5MB</maxFileSize>
                <maxHistory>60</maxHistory>
                <totalSizeCap>10GB</totalSizeCap>
            </rollingPolicy>
            <encoder>
                <pattern>${PATTERN}</pattern>
            </encoder>
        </appender>

        <root level="info">
            <appender-ref ref="console"/>
            <!--<appender-ref ref="syslog"/>-->
        </root>

        <logger name="freemarker.cache" level="OFF"></logger>
        <logger name="com.jsf.database.mapper" level="DEBUG"></logger>
        <logger name="com.jsf.mapper" level="DEBUG"></logger>
    </springProfile>

    <!-- 生产环境 -->
    <!-- INFO+ERROR -->
    <springProfile name="${APPLICATION_SIMPLE}-pro">
        <!-- 记录INFO日志 -->
        <appender name="syslog" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <file>${LOG_PATH}/${FILE_NAME}.log</file>
            <filter class="ch.qos.logback.classic.filter.LevelFilter">
                <level>ERROR</level>
                <onMatch>DENY</onMatch>
                <onMismatch>ACCEPT</onMismatch>
            </filter>
            <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
                <fileNamePattern>${LOG_PATH}/%d{yyyy-MM-dd}/${FILE_NAME}.%i.log</fileNamePattern>
                <maxFileSize>5MB</maxFileSize>
                <maxHistory>60</maxHistory>
                <totalSizeCap>10GB</totalSizeCap>
            </rollingPolicy>
            <encoder>
                <pattern>${PATTERN}</pattern>
            </encoder>
        </appender>

        <!-- 记录Error日志 -->
        <appender name="errorlog" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <file>${LOG_PATH}/${FILE_NAME}.error.log</file>
            <filter class="ch.qos.logback.classic.filter.LevelFilter">
                <level>ERROR</level>
                <onMatch>ACCEPT</onMatch>
                <onMismatch>DENY</onMismatch>
            </filter>
            <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
                <fileNamePattern>${LOG_PATH}/%d{yyyy-MM-dd}/${FILE_NAME}.%i.ERROR.log</fileNamePattern>
                <maxFileSize>2MB</maxFileSize>
                <maxHistory>60</maxHistory>
                <totalSizeCap>1GB</totalSizeCap>
            </rollingPolicy>
            <encoder>
                <pattern>${PATTERN}</pattern>
            </encoder>
        </appender>

        <logger name="com.jsf.database.mapper" level="OFF"></logger>
        <logger name="com.jsf.mapper" level="OFF"></logger>

        <root level="INFO">
            <appender-ref ref="syslog"/>
            <appender-ref ref="errorlog"/>
        </root>
    </springProfile>

</configuration>